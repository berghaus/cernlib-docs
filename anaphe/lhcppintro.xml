<?xml version="1.0" encoding="ISO-8859-1"?>
<!-- -*- DocBook -*- -->
<!-- 	$Id: htldb.xml,v 1.1 2000/04/19 15:13:08 goossens Exp $	 -->
<!DOCTYPE book PUBLIC "-//Norman Walsh//DTD DocBk XML V3.1.4//EN"
          "/usr/local/share/docbookxml/4.11/docbookx.dtd" [
 <!ENTITY xmltex "<application>xmltex</application>">
 <!ATTLIST book xmlns   CDATA #IMPLIED >
 <!ATTLIST book xmlns:m CDATA #IMPLIED >
 <!ENTITY % local.informal.class "| informalmmlequation">
 <!ENTITY % local.formal.class "| mmlequation">
 <!ENTITY % local.tech.char.class "| method">
 <!ELEMENT method (#PCDATA)>
 <!ENTITY % local.bibliocomponent.mix "| note">
 <!ENTITY % local.figure.attrib "loc CDATA #IMPLIED">
 <!-- 
    <!ENTITY % local.para.class "|listpara"> 
    <!ELEMENT listpara (%para.char.mix; | %para.mix;)*> 
 -->
 <!ENTITY % equation.content "(math+)">
 <!ENTITY % inlineequation.content "(math+)">
 <!ENTITY % mathml SYSTEM 
   "/afs/cern.ch/user/g/goossens/xmltex/spqrtalks/gut2000/docbook/mathmldtd/mathml2.dtd">
 <!ATTLIST math xmlns CDATA #FIXED "http://www.w3.org/1998/Math/MathML">
 <!ENTITY QT  "Qt">
 <!ENTITY XML  "XML">
 <!ENTITY LHCPP  "Anaphe">
 <!ENTITY NICE "Nice">
 <!ENTITY OBJ  "Objectivity/DB">
 <!ENTITY UNIX "Unix">
 <!ENTITY WNT  "Windows/NT">
 <!ENTITY % local.programlisting.attrib '
     font        CDATA           #IMPLIED '>
 <!ENTITY % tbl.tgroup.att       "preamble CDATA #IMPLIED">
 <!ENTITY % bodyatt              '
     loc         CDATA           #IMPLIED 
     preamble    CDATA           #IMPLIED '>
<!-- load MathML -->
<!--%mathml;-->
]>
<book>
<bookinfo>
<title>Analysis for Physics Experiments (Version 2.0.1)</title>
<authorgroup>
<author>
<firstname>Andreas</firstname>
<surname>Pfeiffer</surname>
<affiliation>
<orgname>CERN IT/API</orgname>
</affiliation>
</author>
</authorgroup>
<pubdate>June 2000</pubdate>

<!--
This manual has been marked up using <emphasis>&XML;</emphasis> - the
eXtensible Markup Language.  (Is anything else relevent? Perhaps:

Pending the wide-spread availability of XML-capable browsers and
WYSIWYG editors, HTML and PostScript versions of this document have
been produced using ...
-->
<contrib>
Thanks to all contributors to the Anaphe system.
</contrib>
</bookinfo>
<!--1-->
<chapter id="H1PresentingLHCPP">
<title>Presenting &LHCPP;</title>

<sect1>
<title>A short historical introduction</title>
<indexterm><primary>History of &LHCPP;</primary></indexterm>
<indexterm><primary>&LHCPP;!history</primary></indexterm>

<para>In 1995 a working group, called <emphasis>&LHCPP;</emphasis>,
consisting of representatives of IT Division's ASD Group and of the
various LHC experiments, was created to investigate how the
approximate equivalent of the current CERNLIB environment could be
provided in the LHC era. Although the primary objectives of the
discussions concentrated on proposing solutions for future LHC
experiments, it is essential that other HEP experiments which are
coming online in the next couple of years will also be able to benefit
from the proposed strategy.</para>

<para>It is clear that (industry) standard solutions should be used
whenever possible. This is nothing new since in the past commercial
libraries or programs, such as GKS/GTS, Numerical Algorithms Group
(NAG) libraries, Phigs, Historian, and CMZ) have been used in the
CERNLIB environment.  Intensive investment of manpower should only be
made in HEP-specific developments, where the needed functionality
cannot be obtained <emphasis>off the shelf</emphasis> at affordable
prices. An instance of such a HEP development is the CLHEP class
library, which is also a nice example of reuse.</para>
<indexterm><primary>CERNLIB</primary></indexterm>
<indexterm><primary>NAG</primary></indexterm>
<indexterm><primary>Numerical Algorithms Group Ltd</primary></indexterm>
<indexterm><primary>GKS</primary></indexterm>
<indexterm><primary>GTS</primary></indexterm>
<indexterm><primary>Phigs</primary></indexterm>
<indexterm><primary>Historian</primary></indexterm>
<indexterm><primary>CMZ</primary></indexterm>
<indexterm><primary>CERNLIB</primary></indexterm>

<para>Working closely with the LHC collaborations and other HEP
Laboratories in 1996 and 1997 an interim strategy was defined and a
number of licences for the commercial components was obtained.  When
several <emphasis>a priori</emphasis> solutions were available, a study was made
to determine which was the most suited in the HEP context.  We also
tested the proposed solutions at a few sites and ensured that it is a
workable environment.</para>
</sect1>

<sect1>
<title>Objectives</title>

<para>The main objective of &LHCPP; is to satisfy the requirements of the
LHC experiments in terms of the overall software environment that
today is provided by CERNLIB, as requested in these experiments'
<emphasis>Computing Technical Proposals</emphasis></para>
<indexterm><primary>CERNLIB</primary></indexterm>

<para>This translates into the following key points for the short to
medium term:</para>

<itemizedlist> 
<listitem><para>identify and provide key HEP-specific functions;</para></listitem>
<listitem><para>define affordable solutions for the non-HEP-specific parts;</para></listitem>
<listitem><para>monitor the non-HEP world for possible future useful
software;</para></listitem>
<listitem><para>study and understand the requirements of the LHC experiments for
C++-based mathematical libraries, and evaluate existing and future
developments, both commercial and otherwise in this area;</para></listitem>
<listitem><para>study the requirements for a minimisation package
(Minuit-replacement);
<indexterm><primary>Minuit</primary></indexterm>
<indexterm><primary>Minimisation!Minuit</primary></indexterm>
</para></listitem>
<listitem><para>undertake a number of pilot projects with the experiments 
to test the overall functionality of the &LHCPP; environment;</para></listitem>
<listitem><para>supplement, where necessary, the existing documentation, both 
printed and online, with a set of user guides and tutorials;</para></listitem>
<listitem><para>agree with the experiments and other HEP laboratories on
a scheme for managing licenses, so that the best possible deals 
can be negotiated.</para></listitem>
</itemizedlist>

<para>The scope of the &LHCPP; project covers the following:</para>

<itemizedlist>
<listitem><para>foundation level class libraries;</para></listitem>
<listitem><para>mathematical libraries;</para></listitem>
<listitem><para>graphical libraries;</para></listitem>
<listitem><para>visualisation tool-kits, data analysis, histograms;</para></listitem>
<listitem><para>event generators (in collaboration with, e.g., Lund);</para></listitem>
<listitem><para>detector simulation (GEANT-4);
<indexterm><primary>GEANT 4</primary></indexterm>
</para></listitem>
<listitem><para>object persistency (&OBJ; via IT/DB group at present).
<indexterm><primary>RD45 Project</primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
</para></listitem>
</itemizedlist>

<para>The primary focus is on C++-based solutions, although, of course,
developments in the software arena, in particular the increased
importance of Java, are closely watched.</para>

</sect1>
<sect1>
<title>Collaboration with the experiments</title>

<para>The &LHCPP; project is a joint effort between IT Division (mainly
ASD Group), the LHC experiments, plus NA45, Compass,...  Andreas
Pfeiffer is responsible for its overall coordination.</para>

<para>
Regular (bi-weekly) &LHCPP; and RD45 meetings are held in Building
40. This is an ideal forum for communication with the physics
community since its allows us to bring our users regularly up to date
with the latest news. Also, and more importantly, it provides us with
an input channel from the experiments about how they use the software,
which are possible problem areas which have to be addressed, and what
are the future developments they would like to see.  The minutes as
well as material presented on the progress in the various areas are
<ulink 
url="http://wwwinfo.cern.ch/asd/lhc++/meetings/index.html"> available
on the Web</ulink>.
</para> 
<indexterm><primary>Regular meetings (&LHCPP;, RD45)</primary></indexterm>
<indexterm><primary>&LHCPP;!Regular meetings</primary></indexterm>

<para>
Twice a year a formal <ulink
url="http://wwwinfo.cern.ch/asd/lhc++/workshops.html">&LHCPP;
Workshop</ulink> takes place where progress reports are presented by
all HEP-wide collaborations who are using &LHCPP; software. This
Workshop provides an efficient forum for feedback from the experiments
and permits us to steer long-term development in the right direction
by taking into account constraints and requirements of as wide a user
base as possible.
</para>
<indexterm><primary>&LHCPP;!workshop</primary></indexterm>
<indexterm><primary>Workshop (&LHCPP;)</primary></indexterm>

</sect1>
<sect1>
<title>Current Situation</title>

<para>
By using commodity solutions where-ever possible, we ensure that
the proposed solutions are widely used, well-debugged and well
documented, and are also more affordable. These solutions are being
complemented by HEP-specific components, where needed, by building a
HEP user-layer on top of standards-conforming products.
</para>

<para>
To ensure that the commercial components work well together, the
&LHCPP; strategy closely adheres to standards - both
<emphasis>de-facto</emphasis> and <emphasis>de-jure</emphasis>.
Examples of <emphasis>de-jure</emphasis> standards include the
<ulink
url="http://www.objectspace.com/Products/CCS/Standards/standards.html">
Standard C++ Library</ulink> and ODMG-compliant Object Database
Management Systems (ODBMS), while instances of
<emphasis>de-facto</emphasis> standards are industry standard graphics
packages, such as OpenGL, Open Inventor, all originally from Silicon
Graphics (SGI).
<indexterm><primary>Standard Library</primary></indexterm>
<indexterm><primary>ODBMS</primary></indexterm>
<indexterm><primary>Object Database Management System</primary></indexterm>
<indexterm><primary>OpenGL</primary></indexterm>
<indexterm><primary>Open Inventor</primary></indexterm>
<indexterm><primary>SGI</primary></indexterm>
<indexterm><primary>Silicon Graphics</primary></indexterm>
</para>

<para>
Table <xref linkend="tab-layer"/> below shows this layered structure
more schematically.  Licenses for all commercial components are
available at CERN, where the software has been installed on mainstream
&UNIX; platforms (Linux, HP, and Sun) on AFS in
<filename>/afs/cern.ch/sw/lhcxx</filename>, while on &NICE;/&WNT; it is
available under <filename>z:\p32\lhcxx</filename>.
<indexterm><primary>AFS</primary></indexterm>
<indexterm><primary>&WNT;</primary></indexterm>
<indexterm><primary>&NICE;</primary></indexterm>
</para>

<para>
<table id="tab-layer" loc="h">
<title>Layered structure of &LHCPP; system</title>
<indexterm><primary>NAG</primary></indexterm>
<indexterm><primary>GEANT 4</primary></indexterm>
<tgroup cols="1" colsep="1" rowsep="1" preamble="|c|">
<tbody>
<row><entry>GEANT-4, MCLIBS++</entry></row>
<row><entry>OpenGL, Open Inventor </entry></row>
<row><entry>HepFitting and  GEMINI</entry></row>
<row><entry>NAG C library (with C++ headers)</entry></row>
<row><entry>CLHEP</entry></row>
<row><entry>HTL</entry></row>
<row><entry>HEPODBMS</entry></row>
<row><entry>ODMG, ODBMS (&OBJ;) + persistent STL</entry></row>
<row><entry>Standard C++ Libraries</entry></row>
</tbody>
</tgroup>
</table>
</para>

<para>
All of the commercial &LHCPP; components come with excellent online
documentation. In most cases, printed documentation, often in the form
of published books, is also available and can be bought from the
<emphasis>Computing Bookshop</emphasis> in IT Division at
CERN. HEP-specific examples and other information specific to the HEP
environment is clearly not available from the vendors.
</para>

<para>
The main purpose of the present manual is to provide a tutorial
introduction to the use of &LHCPP; tools for physicist new to the &LHCPP;
computing paradigm.  The current guide describes the present state of
some of the HEP extensions.  Their precise form and application
program interface (API) probably needs to be refined or extended in
a few places. Therefore we invite all users of the &LHCPP; software to
forward their comments and suggestions to the &LHCPP; team,
preferably at the &LHCPP; regular meetings mentioned above.
</para>
<indexterm><primary>Regular meetings (&LHCPP;, RD45)</primary></indexterm>
<indexterm><primary>&LHCPP;!Regular meetings</primary></indexterm>

</sect1>
<sect1>
<title>An overview of the commercial components</title>

<para>The commercial components of &LHCPP; are chosen because they offer a
coherent set of inter-operable solutions. They are built on standards
and often come as part of the standard hardware or software bundled
with the computer. Cost effectiveness has also been optimised both
for CERN and for the general CERN HEP program participants.
</para>

<sect2>
<title>OpenGL</title>
<indexterm><primary>OpenGL|(</primary></indexterm>

<para>
<ulink url="http://www.sgi.com/Products/Dev_environ_ds.html">
<emphasis>OpenGL</emphasis></ulink> is an industry standard for
graphics. It is vendor-neutral and multi-platform, and is optimised
for building environments for developing 2D and 3D visual
applications. Several vendors already offer a hardware implementation
of the standard, thus ensuring that rendering speed will be optimal.
</para>

<para>
The about 250 OpenGL procedures provide a wide range of graphics
features, such as a set of geometric and raster primitives, various
colour modes, display list or immediate mode, viewing and modelling
transformations, lighting and shading, hidden surface removal and
translucency, anti-aliasing, texture mapping, effects using fog,
smoke, or haze, etc.  As all licensed OpenGL implementations are
required to pass a set of conformance tests, and implement the same
specification and language binding document full portability between
multiple platforms is guaranteed.
</para>

<para>
Documentation is available as two books: the <emphasis>OpenGL
Programming Guide</emphasis>, and the <emphasis>OpenGL Reference
Manual</emphasis>, both published by Addison and Wesley (available
from the <emphasis>Computing Bookshop</emphasis> in IT
Division).
</para> 
<indexterm><primary>OpenGL|)</primary></indexterm>

</sect2>
<sect2>
<title>Open Inventor</title>
<indexterm><primary>Open Inventor|(</primary></indexterm>

<para>
<ulink
url="http://www.sgi.com/Technology/Inventor/index.html"><emphasis>Open
Inventor</emphasis></ulink> is an object-oriented 3D toolkit to
provide a comprehensive solution to interactive graphics programming.
Its programming model is based on a 3D scene database optimised to
ease building graphics applications. It includes a large set of
objects, such as cubes, polygons, text, materials, cameras, lights,
track-balls, handle boxes, 3D viewers, and editors.
</para>

<para>
Open Inventor is built on top of OpenGL. It defines a standard file
format (IV) for 3D data interchange and introduces a simple event
model for 3D interaction. Animation is provided with
<emphasis>Engines</emphasis>. Open Inventor offers a convenient
multi-platform 3D graphics development environment, which allows
efficient manipulation of objects in a windows and operating system
independent way.
</para>

<para>
Open Inventor's IV files serve as the basis for the 
<ulink url="http://vrml.wired.com">
<emphasis>VRML (Virtual Reality Modelling Language)</emphasis>
standard</ulink>. The Open Inventor toolkit is conveniently documented
in three books <emphasis>The Inventor Mentor</emphasis>, <emphasis>The
Inventor Toolmaker</emphasis>, and <emphasis>The Open Inventor C++
Reference Manual</emphasis> published by Addison-Wesley (available
from the CERN Computing Bookshop).
</para> 
<indexterm><primary>Open Inventor|)</primary></indexterm>
</sect2>

<sect2>
<title>&OBJ;, the Object Database</title>
<indexterm><primary>&OBJ;|(</primary></indexterm>

<para>
In order to study solutions for storing and handling the multi-Pbyte
data samples expected with LHC, the <ulink
url="http://wwwinfo.cern.ch/asd/cernlib/rd45/index.html"><emphasis>RD45
Project</emphasis></ulink> was established in 1995.  The proposed
solution should also be able to cope with other persistent objects,
such as histograms, calibration monitoring data, etc. It was found
that the best candidate for handling this problem is a <ulink
url="http://www.odmg.org/"><emphasis>ODMG</emphasis> (Object Database
Management Group)</ulink>, compliant object database used together
with a mass storage system, based upon the IEEE reference model for
mass storage systems. After considering a few alternatives, the
presently favoured solution uses <ulink
url="http://www.objy.com/"><emphasis>&OBJ;</emphasis></ulink> and
<ulink url="http://www.sdsc.edu/hpss/"><emphasis>HPSS</emphasis> (High
Performance Storage System)</ulink>.
<indexterm><primary>RD45 Project</primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
<indexterm><primary>HPSS</primary></indexterm>
<indexterm><primary>High Performance Storage System</primary></indexterm>
</para>

<para>
The &OBJ; database provides object-persistency services for GEANT-4
and the experimental data. It must fully support HEP meta-data, not
only the persistent data collections themselves, but it must also
handle the selections producing these collections, and the predicates
themselves. Replication of large database images on local area and
wide area network configurations containing heterogeneous hardware
must allow collaborators all over the world to actively participate in
data analysis. Given the large time scales (the lifetime of the LHC
software will span at least twenty years) schema evolution and
versioning are important aspects which must be taken into account.
&OBJ; comes with a set of administrative tools to ease database
management. &OBJ; also comes with an <emphasis>Advanced Multi-threaded
Server</emphasis> (AMS) and an interface to HPSS.
This provides fast access to data and offers a large performance
improvement when updating data stored in remote databases. It is
expected that each experiment will run starting in 1998 a production
service of one or more of these servers.
<indexterm><primary>GEANT 4</primary></indexterm>
<indexterm><primary>Advanced Multi-threaded Server</primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
<indexterm><primary>AMS</primary></indexterm>
<indexterm><primary>HPSS</primary></indexterm>
</para>

<para>
&OBJ; has a layered logical storage level, with at its top the
<emphasis>federated database</emphasis>. Each federated database logically
contains one or more <emphasis>databases</emphasis>, with the latter containing
the <emphasis>objects</emphasis>, which are clustered, for efficiency, inside
<emphasis>containers</emphasis>. An <emphasis>object</emphasis> itself consists of standard
C++ constructs, variable-size arrays, relationships and references to
other objects, and type constraints. Persistent objects can be created
and deleted dynamically by any application. The data model, or
<emphasis>schema</emphasis> is stored inside the federated database.
<indexterm><primary>Object</primary></indexterm>
<indexterm><primary>Federated database</primary></indexterm>
<indexterm><primary>Database</primary></indexterm>
<indexterm><primary>Container</primary></indexterm>
<indexterm><primary>Data model</primary></indexterm>
<indexterm><primary>Schema</primary></indexterm>
<indexterm><primary>&OBJ;|)</primary></indexterm>
</para>
</sect2>

<sect2>
<title>Mathematical Libraries</title>
<indexterm><primary>Mathematical libraries</primary></indexterm>

<para>
CERN no longer has any in-house mathematician supporting mathematics
libraries. Therefore, we shall have to rely on libraries developed
outside CERN, and it was decided to make the <ulink
url="http://www.nag.co.uk/numeric/CL.html"><emphasis>NAG
C-language</emphasis></ulink> library available.  Although the NAG C
Library provides the basic functionality required by HEP, a small
number of routines (basically special functions) are currently
unavailable.  A future release of the above library is likely to
incorporate these routines.
<indexterm><primary>NAG</primary></indexterm>
<indexterm><primary>Numerical Algorithms Group Ltd</primary></indexterm>
</para>
</sect2>

<sect2>
<title>Statistical Data Analysis: the Gemini package</title>
<indexterm><primary>Gemini</primary></indexterm>
<indexterm><primary>Minimisation!Gemini</primary></indexterm>

<para>
Gemini is a GEneral MINImization and error analysis package
implemented as a C++ class library. Minuit's functionality is provided
in a <emphasis>Minuit-style</emphasis> (even if, internally, another
minimizer may actually do the work) and new functionality offered by
NAG C minimizers is added. Gemini thus provides a unified C++ API both
to standard Minuit and to NAG C family of minimizers. For the common
subset of functionality, it is up to the user which minimization
engine does the work: Minuit or NAG C. The user can easily switch
between various minimizers without essential changes in the
application code. The currently supported set of minimizers (Minuit
and NAG C) can be extended without essential changes in the API.
</para>

<para>
The abstract base class <classname>GEmini</classname> defines an
interface to the common functionality. The
<classname>CMinuit</classname> class is derived from
<classname>GEmini</classname> and provides a Minuit-based
implementation of the GEmini functionality plus Minuit-specific
extensions. Similarly, the <classname>NAGmin</classname> class is
derived from <classname>GEmini</classname> as well and provides a
NAG-based implementation of the <classname>GEmini</classname>
functionality plus NAG-specific extensions.
<indexterm><primary>Minuit</primary></indexterm>
<indexterm><primary>Minimisation!Minuit</primary></indexterm>
</para>

<para>
There is no single class which contains references both to Minuit and
to NAG C, so that orthodox Minuit or Nag C users are not forced to
link the other library.
</para>

<para>
Gemini finds a minimum of an objective function, possibly subject to
general constraints, and performs an error analysis. The concept of
errors is that of Minuit, so that it is the user's responsibility to
properly scale the inversed Hessian, and to properly interpret the
results. Both Hessian based errors and Minos errors are
implemented. Correspondingly, two types of function contours (or
confidence regions, in statistical problems) are available: elliptical
and Minos ones. Minos error analysis is, however, possible only for
bound constraint problems.
</para>

</sect2>
</sect1>

<sect1>
<title>Overview of the HEP-specific components</title>

<para>
Although commercial and public-domain packages offer a great deal of
functionality, there is a clear need to supplement them with
HEP-specific extensions. Some of these extensions take the form of
complete class-libraries, such as CLHEP. Others represent large
toolkits, such as <ulink
url="http://wwwinfo.cern.ch/asd/geant4/geant4.html"><emphasis>GEANT-4</emphasis></ulink>,
in areas such as graphics and visualisation, the basic tools, such as
Open Inventor for basic 3D graphics and &QT; for 2D graphics for
visualisation, need to be extended to cope with the specific needs of
the HEP experiments.
<indexterm><primary>GEANT 4</primary></indexterm>
<indexterm><primary>Open Inventor</primary></indexterm>
<indexterm><primary>&QT;</primary></indexterm>
</para>

<sect2>
<title>HEPODBMS</title>
<indexterm><primary>HEPODBMS|(</primary></indexterm>

<para>
HepODBMS is a set of class libraries built on top of the ODMG C++
interface. Their purpose is to provide a higher level interface than
is specified by the ODMG, to simplify the porting of existing
applications and provide a minimum level of support for
transient-persistent switching. Furthermore, these libraries help to 
insulate applications against  changes between releases from 
a given vendor and between the products of different vendors.
<indexterm><primary>ODMG</primary></indexterm>
<indexterm><primary>HEPODBMS|)</primary></indexterm>
</para>

</sect2>
<sect2>
<title>CLHEP</title>
<indexterm><primary>CLHEP|(</primary></indexterm>

<para>
The <ulink
url="http://wwwinfo.cern.ch/asd/lhc++/clhep/index.html"><emphasis>CLHEP</emphasis>
project</ulink> was initiated at CHEP'92; it intends to provide
<emphasis>foundation level</emphasis> classes required in HEP. At
present they include:
<itemizedlist>
<listitem><para><classname>Alist</classname> for lists and list iterators;</para></listitem>
<listitem><para><classname>Combination</classname>;</para></listitem>
<listitem><para><classname>Geometry</classname> for vectors, rotations, transformations;</para></listitem>
<listitem><para><classname>Matrix</classname> for matrix manipulations;</para></listitem>
<listitem><para><classname>Random</classname> for random numbers;</para></listitem>
<listitem><para><classname>String</classname> for different string types;</para></listitem>
<listitem><para><classname>Units</classname> for system of units and physical constants;</para></listitem>
<listitem><para><classname>Vector</classname> for vector operations (3-vector and Lorentz-type).</para></listitem>
</itemizedlist>
</para>

<para>
CLHEP became formally part of &LHCPP; in 1995. The first official release
of CLHEP (V1.0) took place in April 1997 (CHEP'97). CLHEP-based
classes will be integrated in the beta-release of GEANT 4 early 1998.
The complete user documentation, with a detailed description of 
all classes is being written and will be available by the end of 1997.
<indexterm><primary>GEANT 4</primary></indexterm>
<indexterm><primary>CLHEP|)</primary></indexterm>
</para>

</sect2>

<sect2>
<title>The HTL class library</title>

<para>
The HTL class library provides Object Oriented histograms.
They come in two versions:
<itemizedlist>
<listitem><para>Persistent histograms (based on &OBJ;)</para></listitem>
<listitem><para>Transient histograms (text file I/O)</para></listitem>
</itemizedlist>
</para>

<para>
&XML; based persistency for Transient HTL is currently under study.
<indexterm><primary>&XML;</primary></indexterm>
</para>

</sect2>

<sect2>

<title>HepVis</title>
<indexterm><primary>HepVis|(</primary></indexterm>

<para>
The goal of the <ulink
url="http://physics.web.cern.ch/Physics/Workshops/hepvis/"><emphasis>HepVis
Project</emphasis></ulink> is to create and distribute a toolkit
library consisting of graphical objects capable of representing the
most common entities of a collider physics experiment. Previous
experience has shown that mere representations of objects on a
workstation screen is insufficient, and that native support for
picking objects with user-defined actions, and a high-degree of
interactivity, both local and global, is needed.  Therefore, the
HepVis toolkit is being implemented as an extension to Open Inventor,
providing common physics objects as subclasses or as real extensions.
Only the graphical representation of the objects will be defined,
leaving it up to the experiments to define physics objects and their
behaviour, and whether to integrate these with the graphical objects
in question.
<indexterm><primary>HepVis|)</primary></indexterm>
</para>

</sect2>

</sect1>

<sect1 id="S-GNATS">
<title>Problem Reporting</title>

<para>
Due to the phase out of the GNATS problem reporting system at Cern, users 
should submit their problem reports by sending a mail to 
<email>Heplib.Support@cern.ch</email>.
</para>

</sect1>
</chapter>

<!--filename=LHCPPObjectModel.html-->
<chapter id="H1LHCPPObjectModel">
<title>&LHCPP; Object Model</title>

<sect1>
<title>A historical digression: Ntuples and PAW</title>

<para>
During the past decade, many HEP experiments  have based their
interactive data analysis on the following steps
(see the top half of Figure <xref linkend="NTUPLETAGDB"/>).
</para>

<figure id="NTUPLETAGDB" float="1" loc="!h">
<title>The Ntuple and TagDB models</title>
<indexterm><primary>Tag</primary></indexterm>
<indexterm><primary>Ntuple</primary></indexterm>
<indexterm><primary>Data model</primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
<graphic width="50%" fileref="ntupletagdb"/>
</figure>

<orderedlist>
<listitem><para>
<emphasis>Raw and reconstructed</emphasis> data are stored in <emphasis>banks</emphasis> in an
experiment-specific hierarchical format.  Most of the time one uses
many different files on several distinct hosts.
</para></listitem>
<listitem><para>
These data are <emphasis>distilled</emphasis> and <emphasis>reclustered</emphasis> to obtain a
more compact and thus more efficient representation. This permits a
significant speed-up for the down-stream analysis compared to using
the data in their raw form as described in point 1.  This format
corresponds to the so-called HBOOK Ntuples.  One drawback of this
method is that the direct relation to the raw <emphasis>event data</emphasis> is
lost.
<indexterm><primary>HBOOK</primary></indexterm>
<indexterm><primary>Ntuple</primary></indexterm>
</para></listitem>
<listitem><para>
Ntuple files are analysed <emphasis>interactively</emphasis> with programs
like PAW. Plots of physics variables are produced by extracting
information contained in one or more of the Ntuple rows or columns,
binning them in HBOOK histograms and then operating on these histograms
to obtain the best representation. 
<indexterm><primary>HBOOK</primary></indexterm>
</para></listitem>
</orderedlist>

<para>
The advantage of Ntuples is that their format is known and simple enough, 
so that a general purpose analysis tool, such as PAW can cope with data
coming from any experiment. On the other hand, since no link to the
original data exists, Ntuples impose a limitation on the structure of
the data physicists can use for their analysis. On top of that, since
the data were copied from the original files into a dedicated Ntuple
file, each time original dataset changed most Ntuple files had to be
regenerated.
<indexterm><primary>Ntuple</primary></indexterm>
<indexterm><primary>PAW</primary></indexterm>
</para>
<para>
Two kinds of Ntuples exists. <emphasis>Row-Wise Ntuples</emphasis> transform a
complex data structure into a simple tabular form.  <emphasis>Column-Wise
Ntuples</emphasis> on the other hand improve the flexibility of the Ntuple data
model by allowing the definition of variable-length items, but they
still are difficult to use to describe complex data structures, like
those of the reconstructed data.  Moreover, the Ntuple Query language
is rather non-intuitive and complex to master.
</para>

</sect1>
<sect1 id="SNEWDATAMODEL">
<title>The new Data Model</title>

<para>
Most new HEP experiments assume that it will be possible to make both
raw data and reconstructed data available <emphasis>on-line</emphasis> thanks to
the integration between &OBJ; and HPSS. Each experiment will
have its own data model and physicists should be able to
<emphasis>navigate</emphasis> through it. This is a major problem for a
general-purpose Interactive Analysis environment, since, unlike the
Ntuple case, there no longer exists a common and pre-defined data
model shared amongst all experiments. This problem can be solved but there
is no easy way out: the general-purpose tool should be able to access
the arbitrary experiment data model using some kind of run time type
information or the initial data model definition.
<indexterm><primary>HPSS</primary></indexterm>
<indexterm><primary>Ntuple</primary></indexterm>
</para>

<para>
Since all data is supposed to be <emphasis>on-line</emphasis>, the role of the Ntuple
replacement could be quite different. While reasonably small
<emphasis>personal</emphasis> data collections will still exist, the main concern
will probably be how to index large event stores to speed up the
analysis. 
</para>

<para>
The RD45 Project suggested one approach to deal with both problems.
The idea it to speed up queries by defining for each event a <emphasis>Tag</emphasis>, 
i.e., a small collection of its most important physics attributes plus
an association with the event where the Tag data come from. Such
<emphasis>Concrete</emphasis> Tags contain copies of data members of a 
persistent data class. A collection of tag objects 
is saved together in a Tag Database, something 
intermediate between an Event Directory and an Ntuple.
Since they are globally defined for the whole experiment, concrete
tags can be optimized so that they offer a very efficient way to make
initial cuts on attributes, thus achieving a high degree of
selectivity.  On top of that, at any moment you are able to cross the
association to the event if you want to retrieve any other details
about the full event, which are not contained in the Tag (see bottom
part of Figure <xref linkend="NTUPLETAGDB"/>).
<indexterm><primary>Tag</primary></indexterm>
<indexterm><primary>Event</primary></indexterm>
<indexterm><primary>RD45 Project</primary></indexterm>
<indexterm><primary>Event association</primary></indexterm>
<indexterm><primary>Concrete tag</primary></indexterm>
<indexterm><primary>Tag!concrete</primary></indexterm>
<indexterm><primary>Tag!database</primary></indexterm>
<indexterm><primary>Ntuple</primary></indexterm>
<indexterm><primary>Event association</primary></indexterm>
</para>


<para>
The <emphasis>top part</emphasis> of the figure shows schematically
the present <emphasis>traditional</emphasis> approach. The event data
(raw, reconstructed events, calibration constants, etc.) are
represented at the left hand side . They are distributed over many
files residing on various hosts.  An <emphasis>ad-hoc</emphasis>
program reads a set of interesting quantities in these files and
writes the retrieved information into an Ntuple file.  In this Ntuple
file data are reclustered most of the time according to a simple table
structure (more complex arrangements are, of course, possible). As the
Ntuple file format is known, interactive visualisation programs can
efficiently read these data files, thus allowing a fast and convenient
physics data analysis system to be set up. Note, however, that these
Ntuple files are completely disconnected from the original data, so
that it is impossible to automatically update in the Ntuple files
information which changes in the original. Also, it is not possible to
retrieve transparently from the original files data which were not
saved in the Ntuple when it was created.
</para>

<para>
The <emphasis>lower part</emphasis> of the picture figure what the
situation looks like in the Tag model. In this case often-used data
are once more reclustered (using experiment-wide concrete tags or
user-defined generic tags), but all data remain inside the same
federated database, and there exists a bidirectional link between the
reclustered and the original data. In this way, when the original data
are reprocessed, it is trivial to update the tag data, so that they
remain always up-to-date.  Conversely, when for a given event the
information in the tag database is not sufficient, then the link to
the complete event data allows you to retrieve the supplementary
information in a convenient and straighforward way <emphasis>on the
fly</emphasis>.
<indexterm><primary>Federated database</primary></indexterm>
<indexterm><primary>Database</primary></indexterm>
<indexterm><primary>Ntuple</primary></indexterm>
</para>

<para>
In general the selection of <emphasis>key</emphasis> attributes characterising 
events will be made by the experiment or group, so that concrete tags
are mostly defined for experiment-wide or
workgroup-wide data sets. However, individual physicists have
the possibility to define their own simpler data collection by using
the <emphasis>Generic Tag</emphasis> mechanism. This second light-weight procedure
allows you to define a tag <emphasis>on the fly</emphasis>, without creating a
persistent class. Compared to the concrete tag, there is, of course, a
small performance penalty, but this is most of the time balanced by
an increased flexibility, since at any time new fields can be added to
the tag and the association to the complete event data remains
available. Presently, both the concrete tag
and the generic tag are defined in a C++ program before being
used in the Interactive Analysis framework.
<indexterm><primary>Tag!concrete</primary></indexterm>
<indexterm><primary>Event association</primary></indexterm>
<indexterm><primary>Tag!concrete</primary></indexterm>
<indexterm><primary>Concrete tag</primary></indexterm>
<indexterm><primary>Generic tag</primary></indexterm>
<indexterm><primary>Tag!generic</primary></indexterm>
</para>
</sect1>

<sect1>
<title>Implementing the Data Model: explorable collections</title>

<para>
When creating a tag (either generic or concrete) a description of its
fields (name and type) must be provided. This information is used
later to access the data. The set of individual
tags is called an <emphasis>Explorable Collection</emphasis>,
i.e., a collection of objects implementing an access interface suitable for
an Interactive Analysis Tool.
<indexterm><primary>Explorable collection</primary></indexterm>
<indexterm><primary>Tag</primary></indexterm>
</para>

</sect1>
</chapter>

<!--filename=SetUpUserEnvironment.html-->
<chapter id="H1SetUpUserEnvironment">
<title>Setting up the user environment</title>

<para>
The &LHCPP; environment is defined by a set of environment variables which 
define where to retrieve tools, libraries , include files etc.
Depending on the flavour of the &UNIX; shell used (Bourne o csh), different
commands are used to define such variables. In order to have the environment
properly set up at any new login, those commands must be recorded in a
startup script which is then executed when the user logs in.
The name of these script depends on the shell flavour as well.
</para>

<sect1>
<title>Environment variables required by &LHCPP;</title>
<indexterm><primary>environment</primary></indexterm>

<para>
These are the environment variables &LHCPP; relies on:
<itemizedlist> 
<listitem><para><envar>LHCXXTOP</envar>, the location where &LHCPP; is installed;</para></listitem>
<listitem><para><envar>PLATF</envar>, the specific computing platform ;</para></listitem>
<listitem><para><envar>LHCXX_REL_DIR</envar>, the release of &LHCPP; in use;</para></listitem>
<listitem><para><envar>OBJY_VERS</envar>, the release of &OBJ; in use.</para></listitem>
</itemizedlist>
These environment variables are used to locate all &LHCPP; components.
&LHCPP; provides startup scripts to set reasonable defaults for those
variables, but in some cases the user may want to override them. The
next sections will explain how to setup the user environment depending
on the flavour of the active shell.  <ulink
url="http://consult.cern.ch/writeup/shellsintro/"><emphasis>Shell
Support - tcsh and zsh for pedestrians</emphasis></ulink> provides a
comprehensive description of two mainstream shells (tcsh and zsh).
</para>
</sect1>

<sect1>
<title>Setting up the environment for Bourne shell flavour shells </title>
<indexterm><primary>environment</primary></indexterm>

<para>
The Bourne family of &UNIX; shells includes sh, bash, ksh and zsh. The
&LHCPP; environment includes a startup script users have to source to
get the environment set up. This script must be sourced from the
<filename>.profile</filename> system script.  The startup script will
define all the above mentioned environment variables unless they're
already defined. The detection of the plaform in use relies on the
well known environment variable <envar>OS</envar>. If that variable is
not defined and the user did not define <envar>PLATF</envar>
beforehand, the script will assume that the platform is Linux Red Hat
6.1.  To source the &LHCPP; script, add these lines to
<filename>.profile</filename>:
</para>

<programlisting>
<![CDATA[# At Cern LHCXXTOP=/afs/cern.ch/sw/lhcxx
export LHCXXTOP=<where Anaphe is installed>
# Source the startup script. If using versions other than 2.0.1
# just substitute it with the new version.
. $LHCXXTOP/share/LHCXX/2.0.1/install/sharedstart.sh ]]>
</programlisting>

<para>
Please do not define <envar>PLATF</envar> as the AFS variable
<envar>@sys</envar>.  since such variable can be ambigous.
</para>

</sect1>

<sect1>
<title>Setting up the environment for csh shell flavour shells </title>
<indexterm><primary>environment</primary></indexterm>

<para>
The csh family of &UNIX; shells includes csh and tcsh. The
&LHCPP; environment includes a startup script users have to source to get
the environment set up. This script must be sourced from the 
<filename>.login</filename>
The startup script will define all the above mentioned environment variables 
unless they're already defined. The detection of the plaform in use relies
on the well known environment variable <envar>OS</envar>. If such variable
is not defined and the user did not define <envar>PLATF</envar> beforehand,
the script will assume that the platform is Linux Red Hat 6.1.
To source the &LHCPP; script, add these lines to <filename>.login</filename>:
</para>

<programlisting>
<![CDATA[# At Cern LHCXXTOP=/afs/cern.ch/sw/lhcxx
setenv LHCXXTOP <where Anaphe is installed>
# Source the startup script. If using versions other than 2.0.1
# just substitute it with the new version.
source $LHCXXTOP/share/LHCXX/2.0.1/install/sharedstart.csh ]]>
</programlisting>

<para>
Please do not define <envar>PLATF</envar> as the AFS variable
<envar>@sys</envar>.  since such variable can be ambigous.
</para>

</sect1>

<sect1>
<title>How to get a fresh &OBJ; federated database </title>
<indexterm><primary>&OBJ;</primary></indexterm>

<para>
To use some of the &LHCPP; components, &OBJ; is needed. If you do not yet have 
such a database set
up, you should contact your experiment's or group's &OBJ; coordinator,
who will take the necessary steps to register you for database use.
You will then be assigned a <emphasis>Federated Database IDentifier</emphasis>
(FDID), to uniquely identify your federated database to the &OBJ;
servers. This number should be specified when first installing the
database, as described below.
<indexterm><primary>Registering for &OBJ; database use</primary></indexterm>
<indexterm><primary>FDID</primary></indexterm>
<indexterm><primary>Federated database!IDentifier (FDID)</primary></indexterm>
</para>

<para>
When you log on you must check whether the lock server is running. You
can do that with the command: <command>oolockmon</command>. If it is
NOT running, you may start it with the command: <command>oolockserver
-noauto</command>.  If it is running and you want to kill it you issue
the command <command>ookillls</command> .
</para>

<para>
To install your own user federated database you can do the following 
(Bourne flavour shells): 
</para>

<programlisting>
<![CDATA[export MY_FDID=<a valid number in the range allocated to you> 
export OO_FD_BOOT=<name of your choice; preferably full path> 
$HEP_ODBMS_DIR/etc/getdb $LHCXXTOP/share/HTL/1.1.1.1/schema/HISTO $OO_FD_BOOT $MY_FDID ]]>
</programlisting>

<para>
For csh flavour shells: 
</para>

<programlisting>
<![CDATA[setenv MY_FDID <a valid number in the range allocated to you> 
setenv OO_FD_BOOT <name of your choice; preferably full path> 
$HEP_ODBMS_DIR/etc/getdb $LHCXXTOP/share/HTL/1.1.1.1/schema/HISTO $OO_FD_BOOT $MY_FDID ]]>
</programlisting>

<para>
Once you got your database, do not forget to add the command defining where 
federated database is to the proper system setup script, i.e. :
</para>

<para>
For Bourne flavour shells add to <filename>.profile</filename>
</para>

<programlisting>
<![CDATA[export OO_FD_BOOT=<name of your choice; preferably full path> ]]>
</programlisting>

<para>
For csh flavour shells add to <filename>.login</filename>
</para>

<programlisting>
<![CDATA[setenv OO_FD_BOOT <name of your choice; preferably full path> ]]>
</programlisting>

<para>
To check wheter the database has been installed properly, try:
</para>

<programlisting>
oodumpcatalog $OO_FD_BOOT
</programlisting>

</sect1>

<sect1>
<title>Installation troubleshooting</title>
<indexterm><primary>Installation!troubleshooting</primary></indexterm>
<indexterm><primary>Troubleshooting</primary></indexterm>

<para>
Installation procedure failure is usually due to one of the following
reasons.
</para>

<itemizedlist>
<listitem>
<para> 
<emphasis>Missing access rights to the Objectivity
package.</emphasis> In this case you should get your Objectivity
licence before trying again.  </para></listitem> <listitem><para>
<emphasis>Lockserver running in autorecovery mode.</emphasis> Use the
&UNIX; <command>ps</command> command to find out the lockserver's
running mode:
<programlisting>
ps -ef | grep ools
</programlisting>
If you see something like:
<programlisting>
dinofm 20536 1 0 Oct 27 ? 1:37 ools
</programlisting>
restart the lockserver in the proper mode:
<programlisting>
> ookillls
> oolockserver -noautorecovery
> ps -ef | grep ools
</programlisting>
where the <command>ps</command> command should show something like:
<programlisting>
dinofm 20536 1 0 Oct 27 ? 1:37 ools -OO_NO_AUTOREC
</programlisting>
</para></listitem>
</itemizedlist>
</sect1>
</chapter>

<!--filename=AccessOBJDatabase.html-->
<chapter id="H1AccessOBJDatabase">
<title>Accessing the &OBJ; database</title>

<sect1>
<title>What does the user have to know about the database?</title>

<para>
Ideally, the hierarchical structure of the data storage should be
completely transparent to the average user. Therefore, the &LHCPP; Team
has done its best to hide the impact of the database on the C++
user code to a minimum. However, it is best that the users of the
modules are aware of some basic principles, and how they relate to the
experimental data model used by the various analysis programs.
</para>

<para>
Let we have a look at Figure <xref linkend="STORAGEUSER"/>.
It shows the storage hierarchy used to store event data at the
left, together with the user's view of these data at the right.
</para>

<figure id="STORAGEUSER" loc="ht">
<title>The storage hierarchy and the user view</title>
<graphic width="80%" fileref="storage-user"/>
</figure>

<para>
We start with the user's view (right hand side of the picture).  The
user likes to think in terms of events (the octagons), and wants to
deal with, for instance reconstructed tracks (the triangles), hits in
the forward calorimeter (the diamonds), or the calibration for the TPC
(the pentagons), etc. Users should not be directly concerned (apart
perhaps for efficiency considerations) how these various data elements
are actually stored in files and distributed over a network. They
prefer to have a <emphasis>logical</emphasis> view of their event and
navigate between its various componenents in a transparent way. It is
up to the data administrator to make sure that the data are stored in
a way optimising performance and throughput for the end user.
</para>

<para>
This is possible using an object oriented database system, such as
&OBJ; (left hand side of the picture). All data are kept in one
<emphasis>federated database</emphasis>, which is basically just a file containing
the catalog of the database files and the hostnames where they
reside. It also contains the <emphasis>schema</emphasis> (object model) used by
the data in the various databases.
<indexterm><primary>Federated database</primary></indexterm>
<indexterm><primary>Database</primary></indexterm>
<indexterm><primary>Schema</primary></indexterm>
</para>

<para>
The <emphasis>databases</emphasis> themselves are also separate files, which can
reside on different nodes and they can consist of multiple
<emphasis>containers</emphasis>, that can be thought of a contiguous areas on a
file.
</para>
<indexterm><primary>Data model</primary></indexterm>
<indexterm><primary>Container</primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
<para>
Finally, each container consists of one or more <emphasis>persistent</emphasis>
objects (e.g., histograms, reconstructed tracks, fits). As seen in the
picture, the mapping of the event to its components is very flexible,
allowing different parts of an event to reside in different
containers, and/or databases (even on remote nodes). Moreover, since
the end users only access the full data through the logical structure,
they are never affected by changes in the physical layout of the
database.
</para>

</sect1>

<sect1>
<title>Getting access to an &OBJ; database</title>

<para>
In 1999 a central service will be run for the various experiments using &OBJ;
to provide access to their databases
from various platforms using AMS. However, at present, it is necessary to
associate a federated database with a given machine, so that you must
always connect to that same machine if you want to access that
database.
<indexterm><primary>AMS</primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
<indexterm><primary>Federated database</primary></indexterm>
<indexterm><primary>Database</primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
</para>

<para>
In particular, when working on a cluster (such as hpplus) you must
remember the real node name (e.g., <literal>hpplus16</literal>, as in
the example in the previous chapter) of the machine which you used to
create the database.  When you want to use the database in a later
session, you must always connect to that node, otherwise you will not
be able to access your data (unless your experiment is running &OBJ;'s
AMS, a facility to share databases across the network).
</para>
<indexterm><primary>&OBJ;</primary></indexterm>

<para>
The first step (after creating the database) is to tell &OBJ;
where it can be found. This is done with the environment variable
<envar>OO_FD_BOOT</envar>, which should be set to the full path name
of the boot file of the database that you want to access.  This boot
file is actually a small ASCII file, which contains valuable
information about your federated database.
<indexterm><primary><envar>OO_FD_BOOT</envar></primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
<indexterm><primary>Federated database</primary></indexterm>
<indexterm><primary>Database</primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
</para>
<programlisting>
> more $OO_FD_BOOT 
ooFDNumber=30500
ooLFDNumber=65535
ooPageSize=8192
ooLockServerName=hpplus16
ooFDDBHost=hpplus16
ooFDDBFileName=/afs/cern.ch/user/g/goossens/HP-UX/explorer/HEPEXP.FDDB
ooJNLHost=hpplus16
ooJNLPath=/afs/cern.ch/user/g/goossens/HP-UX/explorer
</programlisting>
<para>You should <emphasis>NEVER</emphasis> change its contents!</para>
<para>
In particular, changing the path of the federated database in this
file after you moved it will <emphasis>not</emphasis> work.
<indexterm><primary>Federated database</primary></indexterm>
<indexterm><primary>Database</primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
</para>

<para>
Once the <envar>OO_FD_BOOT</envar> variable is set correctly, you can
run the &OBJ; management tools. For instance the program
<application>oodumpcatalog</application> displays the catalog, showing
the different databases associated to the current federated database.
<indexterm><primary><application>oodumpcatalog</application></primary></indexterm> 
<indexterm><primary>Federated database</primary></indexterm>
<indexterm><primary>Database</primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
</para>
<programlisting>
<![CDATA[> oodumpcatalog

Objectivity/DB (TM) List Database Files Utility, Version 4.0.2
Copyright (c) Objectivity, Inc 1990, 1996. All rights reserved.

FD Name   = HEPEXP
FD ID     = 30500
FD File   = hpplus16::/afs/cern.ch/user/g/goossens/HP-UX/explorer/HEPEXP.FDDB
Boot File = hpplus16::/afs/cern.ch/user/g/goossens/HP-UX/explorer/HEPEXP
Jnl Dir   = hpplus16::/afs/cern.ch/user/g/goossens/HP-UX/explorer
Lock Host = hpplus16

DB Name   = SimpleTestDatabase
DB ID     = 3
DB Image  =
hpplus16::/afs/cern.ch/user/g/goossens/HP-UX/explorer/SimpleTestDatabase.HEPEXP.DB ]]>
</programlisting>

<para>
Thus, in the example above, we see that we need to connect to the node
<literal>hpplus16</literal> (the so-called <emphasis>Lock
Host</emphasis>).  It should also be noted that each federated
database should have a different federated database number to enforce
proper locking management when the same lockserver is used by more
than one federation (e.g., when the lockserver is running on a central
service, such as hpplus).  A series of federated database numbers have
been allocated to experiments and user groups (see <ulink
url="http://wwwinfo.cern.ch/asd/cernlib/rd45/recommendations/dba.html">
<emphasis>Draft recommendations concerning Objectivity/DB DBA
issues</emphasis></ulink> for a proposed list). As explained above, when
registering as a database user with your experiment's or group's
&OBJ;'s coordinator, you get a unique number assigned to ensure the
uniqueness of the federated database number.

<indexterm><primary>RD45 Project</primary></indexterm>
<indexterm><primary>Federated database</primary></indexterm>
<indexterm><primary>Database</primary></indexterm>
</para>

</sect1>

<sect1 id="H2AccesssOBJ">
<title>Accessing the &OBJ; from inside a C++ program</title>

<para>
After the initial installation, you have a federated database, which
has no associated databases yet. This can be seen by using the &OBJ;
tool <application>ootoolmgr</application>
(<application>oobrowse</application> on &WNT;), which allows you to
browse the contents of all databases (down to the object level) in a
federated database.  If you want to run
<application>ootoolmgr</application> just type
<programlisting>
> ootoolmgr
</programlisting>
on the command line. You will then get an &OBJ; panel, as shown
in Figure <xref linkend="OOTOOLMGRPANEL"/>.
<indexterm><primary>Federated database</primary></indexterm>
<indexterm><primary>Database</primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
<indexterm><primary><application>ootoolmgr</application></primary></indexterm>
</para>

<figure id="OOTOOLMGRPANEL" loc="ht">
<title>The <application>ootoolmgr</application> initial panel</title>
<graphic width="50%" fileref="ootoolmgrpanel"/>
</figure>

<para>
Then in the <guimenu>File</guimenu> pull-down menu you choose the
database (most of the time it is enough to click the default setting
at the bottom, which corresponds to the database selected with the
<envar>OO_FD_BOOT</envar> environment variable). Then you can go to
the <guimenu>Tools</guimenu> pull-down menu and choose
<guimenuitem>Browse FD</guimenuitem> at the top. Then you will see the
<interface>&OBJ; - Browse FD</interface> appear, with four main windows,
namely the names of the <emphasis>Databases</emphasis>,
<emphasis>Containers</emphasis>, <emphasis>Basic Objects</emphasis>,
and finally, at the bottom, the contents of the selected object. Just
after initialisation, there are no databases yet, as seen in Figure
<xref linkend="OOTOOLMGREMPTY"/>.
</para>

<figure id="OOTOOLMGREMPTY" loc="ht">
<title>Using the tool <application>ootoolmgr</application></title>
<indexterm><primary><application>ootoolmgr</application></primary></indexterm>
<graphic width="54%" fileref="ootoolmgrempty"/>
</figure>

<para>
Before writing our first C++ program to use the database, let us
first establish three basic rules.
</para>
<orderedlist>
<listitem><para>
One must first establish a connection to the database with the
<method>Init</method> method.
<indexterm><primary><method>Init</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>Init</method></primary></indexterm>
</para></listitem>
<listitem><para>
<emphasis>Transactions</emphasis> are used to retrieve or store persistent
objects.
<indexterm><primary>&OBJ;!transaction</primary></indexterm>
<itemizedlist>
<listitem><para>
A transaction is set up using the <method>startUpdate</method>
or <method>startRead</method> methods.
<indexterm><primary><method>startUpdate</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>startUpdate</method></primary></indexterm>
<indexterm><primary><method>startRead</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>startRead</method></primary></indexterm>
</para></listitem>
<listitem><para>
A transaction is terminated using the <method>commit</method>
or <method>abort</method> methods. The <method>commit</method> method
will save all changed objects in the database, whereas  <method>abort</method>
will revert the database to the state before the transaction was
initiated.
<indexterm><primary>&OBJ;!transaction</primary></indexterm>
<indexterm><primary><method>commit</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>commit</method></primary></indexterm>
<indexterm><primary><method>abort</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>abort</method></primary></indexterm>
</para></listitem>
</itemizedlist>
</para></listitem>
<listitem><para>
To access persistent objects <emphasis>smart</emphasis> pointers are provided.
They are indistinguishable from normal C++ pointers, they are merely
declared with a different syntax using <literal>HepRef</literal>, e.g.,
for a 1D histogram we would declare
<indexterm><primary>Smart pointer</primary></indexterm>
<programlisting>
HepRefP(Histo1D) myHisto (...);
</programlisting>
while for a pointer to a non-persistent C++ object you would write
<programlisting>
Histo1D *myHisto ...
</programlisting>
Once you have declared your smart pointers to your persistent object,
all navigation between objects is completely like in the case of
normal pointers; whenever a reference is made to a smart pointer, a
callback to the database will automatically fetch the required
data. Moreover at the end of the transaction all modified objects will
automatically be stored in the database at commit time.
<indexterm><primary>&OBJ;!transaction</primary></indexterm>
</para></listitem>
</orderedlist>
<para>
If, while reading through the examples, you want to know more details
about the HepODBMS classes, you should consult the <ulink
url="http://wwwinfo.cern.ch/asd/lhc++/HepODBMS/reference-manual/HepODBMS.html"><emphasis>Reference
Manual for the HepODBMS package</emphasis></ulink>.
</para>

</sect1>

<sect1>
<title>Manipulating the &OBJ; database and its containers in a C++ program</title>

<para>
To show a few more of the class methods available to manipulate an
&OBJ; database, we can look at the following code.
</para>
<programlisting font="footnotesize">
<![CDATA[/* dbAccess.cpp */
#include "HepODBMS/tagdb/HepTagDbApplication.h"
#include "HepODBMS/tagdb/HepEvent.h"

class dbAccessApp : public HepTagDbApplication {
  // Application inherits session control from HepDbApplication
public:
  // this application implements just one method: run the 
  dbAccessApp(const char *name) : HepTagDbApplication(name)
  {};
  
  int run()
  {
    // print an 
    message("about to initialise the db connection");
    Init();        // initialise the db session
    message("starting an update transaction");
    startUpdate(); // start an update transaction

    // create a new database (file)
    HepDatabaseRef  myDb = db("MyDatabase");

    // if the database ref is not valid:
    // - print a message
    // - exit the application with an error code 
    if (myDb == 0)
      fatal("could not find or create MyDatabase");
    
    // create a new container in this database
    HepContainerRef cont = container("MyContainer"); 
    if (cont == 0 )
      fatal("could not find or create MyDatabase");

    // work with the container and database
    // (e.g. create histograms, tags or other persistent objects)
      
    for (short i=0; i<1000; i++)
    {
      // create a new event in my container
      HepRef(HepEvent) event = new(cont) HepEvent;
      if (event == 0) 
        fatal("could not create a new event");
    }
    message("created 1000 events");

    printContainerMap( ) ;

    // delete the container from the database
    // including all events
    HepDelete(cont);
    warning("deleted the container");

    // delete the database from the federation
    HepDelete(myDb);
    warning("deleted the database");

    // commit all changes made during this transaction
    commit();
    return 0;
  }
  
};

int main(int argc, const char *argv[])
{
  dbAccessApp myApp(argv[0]);  // create an application object
  return myApp.run();    // call it's run method
}]]>
</programlisting>
<indexterm><primary><classname>HepDbApplication</classname> class (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!classes!<classname>HepDbApplication</classname></primary></indexterm>
<indexterm><primary><method>commit</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>commit</method></primary></indexterm>
<indexterm><primary><method>init</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>init</method></primary></indexterm>
<indexterm><primary><method>startupdate</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>startupdate</method></primary></indexterm>
<indexterm><primary><method>fatal</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>fatal</method></primary></indexterm>
<indexterm><primary><method>warning</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>warning</method></primary></indexterm>
<indexterm><primary><method>message</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>message</method></primary></indexterm>
<indexterm><primary><method>HepDelete</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>HepDelete</method></primary></indexterm>
<indexterm><primary><method>printcontainermap</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>PrintContainerMap</method></primary></indexterm>
<para>
The <classname>HepDbApplication</classname> class defines the transaction methods 
<method>abort</method>, <method>commit</method>, <method>startRead</method>, 
<method>startUpdate</method> (described already in Section
<xref linkend="H2AccesssOBJ"/>),
as well as four methods for sending an informative string to the
user console: <method>fatal</method> (prints a fatal error message and
aborts), <method>error</method> and <method>warning</method>,  (prints an 
error and warning message and continue), and
<method>message</method> (just prints a message).
<indexterm><primary>&OBJ;!transaction</primary></indexterm>
<indexterm><primary><classname>hepdbapplication</classname> class (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!classes!<classname>hepdbapplication</classname></primary></indexterm>
<indexterm><primary><method>abort</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>abort</method></primary></indexterm>
<indexterm><primary><method>commit</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>commit</method></primary></indexterm>
<indexterm><primary><method>startread</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>startread</method></primary></indexterm>
<indexterm><primary><method>startupdate</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>startupdate</method></primary></indexterm>
<indexterm><primary><method>fatal</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>fatal</method></primary></indexterm>
<indexterm><primary><method>warning</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>warning</method></primary></indexterm>
<indexterm><primary><method>message</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>message</method></primary></indexterm>
<indexterm><primary><method>error</method> method (HEPODBMS)</primary></indexterm>
<indexterm><primary>HEPODBMS!methods!<method>error</method></primary></indexterm>
</para>
<para>
The <literal>HepDatabaseRef</literal> declaration sets up a database
handle <literal>myDb</literal> using the <method>db</method> method
from the <classname>ooSession</classname> class. Once we have opened a
database, we declare a container with
<literal>HepContainerRef</literal>, which returns us a handle
<literal>cont</literal> using the <method>container</method> method
from the <classname>ooSession</classname> class. The container handle
is then used to store one thousand events of type
<type>HepEvent</type> inside the <literal>for</literal> loop. Just
before we delete our database we print a map of the containers with
the <method>printContainerMap</method> method, which shows the
containers together with their object identifiers (the
<literal>HepSystem</literal> and <literal>ExplorableDescr</literal>
containers are created when HEPODBMS is set up in the
<literal>System</literal> database).  Finally, we delete the container
and database by specifying their respective handles to the
<method>HepDelete</method> method. Below, the output generated by the
above C++ code is shown.
</para>
<programlisting>
dbAccess: about to initialise the db connection
dbAccess: starting an update transaction
dbAccess: created 1000 events
HepSystem --- #3-4-3-1
ExplorableDescr --- #3-5-3-1
MyContainer --- #12-3-1-1
WARNING: dbAccess: deleted the container
WARNING: dbAccess: deleted the database
</programlisting>

</sect1>

<sect1>
<title>&OBJ; administration tools</title>

<para>
&OBJ; provides a whole set of administration tools to manage a
federated database. These tools are described in detail in the
<emphasis>&OBJ; Administration</emphasis> manual. In this section we briefly
describe the more useful from the physicists' point of view.
</para>
<itemizedlist>
<listitem><para><application>oodumpcatalog</application> provides 
summary information about a
    federated database;
<indexterm><primary><application>oodumpcatalog</application></primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
</para></listitem> 
<listitem><para><application>ootoolmgr</application> (<application>oobrowse</application>
    on &WNT;) allows you to browse federated database schema and
    data;</para></listitem>
<listitem><para><application>oocleanup</application> resets pending locks;</para></listitem>
<listitem><para><application>oodeletedb</application> deletes a <emphasis>physical</emphasis> database.</para></listitem>
</itemizedlist>
</sect1>
</chapter>

<!--filename=HistogramTagClasses.html-->

<chapter id="H1HistogramTagClasses">
<title>Histogram and tag classes</title>

<para>
All classes are being documented and a user guide and
reference manual for the available components will be available soon.
In this chapter we shall describe the main characteristics of the
HTL classes and also learn about the tag classes. 
As explained before, ready-to-run examples can be found in the 
following two directories.
</para>
<programlisting>
<![CDATA[# At Cern LHCXXTOP=/afs/cern.ch/sw/lhcxx
$LHCXXTOP/share/HepODBMS/<version>/HepODBMS/examples
$LHCXXTOP/share/HTL/<version>/HTL/examples/ ]]>
</programlisting>
<para>
Each example has its own subdirectory (corresponding to the first part
of the filename, i.e., preceding the suffix <literal>.cpp</literal>,
specified as a comment on the first line of the examples' C++ code in
this manual), which contains the C++ source code in a file with
extension <literal>cpp</literal>, as well as a
<literal>GNUmakefile</literal> which will compile, link and generate
an executable if run with <application>gmake</application>. These
example programs should form an excellent basis to get started writing
your own application programs.
<indexterm><primary>Examples!location</primary></indexterm>
<indexterm><primary>Examples!running \~{}</primary></indexterm>
</para>

<sect1 id="PERSISTENTHISTOS">
<title>The HTL package</title>

<para>
The Persistent HTL Package provides the basic histogramming
functionality of HBOOK along with some additional features.  See
<ulink
url="http://wwwinfo.cern.ch/asd/lhc++/HTL/index.html"><emphasis>HTL -
The Histogram Template Library</emphasis></ulink> for more details.
<indexterm><primary>HBOOK</primary></indexterm>
</para>
</sect1>

<sect1>
<title>Converting an HBOOK file into an &OBJ; database</title>
<indexterm><primary>HBOOK</primary></indexterm>

<para>The program <application>Hbook2Objy</application>
converts histograms contained in an HBOOK file into persistent HTL
histograms that can be saved in an &OBJ; database. Only one- and
two-dimensional histograms are converted, Ntuples are ignored. To
execute the program you should type:</para>

<programlisting>
<![CDATA[$HISTOODIR/bin/Hbook2Objy <hfile> <OBJ-federated-DB>]]>
</programlisting>

<para>
Starting from the histograms in the HBOOK file
<filename>&lt;hfile></filename> the program will create a new database
with as name the name of the HBOOK file <filename>&lt;hfile></filename>
inside the &OBJ; database pointed at by the environment variable
<envar>OO_FD_BOOT</envar>.  If <filename>&lt;hfile></filename> already
exists, then you will be asked whether you want to overwrite the
original file.  
<indexterm><primary>Federated database</primary></indexterm>
<indexterm><primary>Database</primary></indexterm>
<indexterm><primary>&OBJ;</primary></indexterm>
</para>

<para>
It should be noted that the hierarchical (directory) structure of the
HBOOK file is not preserved. Nevertheless, since the name of each
created persistent histogram corresponds to the full path name inside
the HBOOK hierarchy, it is easy to distinguish between histograms with
the same name but coming from different HBOOK directories.  An example
of the translation of a set of HBOOK histograms is shown in Figure
<xref linkend="PAW2HISTOO"/>.  At the top we see some (1D and 2D)
histograms with the HBOOK Directory Browser, and at the bottom the
same histograms after conversion as viewed from the &OBJ; database
with the <application>HistOOgramReader</application> module.
</para>

<figure id="PAW2HISTOO" loc="ht">
<title>Transforming HBOOK histograms into HTL histograms</title>
<indexterm><primary>HBOOK</primary></indexterm>
<indexterm><primary><application>HistOOgramReader</application> module</primary></indexterm> 
<indexterm><primary>HEPExplorer!modules!<application>HistOOgramReader</application></primary></indexterm>
<informaltable preamble="c">
<tgroup cols="1" colsep="0" rowsep="0"  preamble="c">
<tbody>
<row>
<entry><inlinegraphic width="80%" fileref="H2OPaw"/></entry>
</row>
<row>
<entry><inlinegraphic width="80%" fileref="H2OHistOOReader"/></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</figure>
</sect1>

<sect1>
<title>The tag classes</title>
<indexterm><primary>Tag|(</primary></indexterm>

<sect2>
<title>Writing tags</title>

<para>As explained earlier (see Section <xref linkend="SNEWDATAMODEL"/>),
tags are a small collection of the most important physics attributes
of an event plus an association with the event in question.  Tags
provide a natural and efficient syntax for handling event data,
speeding up queries, cuts handling, etc., substantially, while at the
same time offering the possibility to easily access the original full
data. Usually, the event tags are chosen in such a way that a high
degree of selectivity can be obtained by first cutting on attributes
in the event tag, while, if needed, the association to the full event
can be exploited in order to retrieve any other information not
contained in the tag.</para>
<indexterm><primary>Event association</primary></indexterm>
<indexterm><primary>Event association</primary></indexterm>

<para>In workgroup-wide data sets, individual physicists should still be
able to have their own simpler data collection, so an easy-to-use
<emphasis>Generic Tag</emphasis> is defined as well.  Presently, both the Event Tag 
and the Generic Tag have to be created inside a C++ program before using
the Interactive Analysis framework.</para>
<indexterm><primary>Tag!generic</primary></indexterm>

<para>
The data types that can be stored in a tag are <type>long</type> and
<type>short</type> integers, <type>float</type> and <type>double</type> real
numbers, and an 8-bit <type>char</type>.
<indexterm><primary>Explorable collection</primary></indexterm>
</para>

<para>
Examples of the use of tags are given with more details in the <ulink
url="http://wwwinfo.cern.ch/db/objectivity/docs/hepodbms">HEPODBMS
documentation</ulink>.

<indexterm><primary>Tag|)</primary></indexterm>
</para>
</sect2>

<sect2>
<title>Converting HBOOK Ntuples to &OBJ;</title>

<para>
The &LHCPP; environment provides tools to 
<ulink
url="http://wwwinfo.cern.ch/asd/lhc++/TOOLS/ntkit/ntupleconvnew.html">
convert existing HBOOK Ntuples to &OBJ;</ulink>.
</para>
</sect2>
</sect1>
</chapter>

<!--filename=Glossary.html-->
<chapter id="H1Glossary">
<title>Glossary</title>

<variablelist>
<varlistentry>
<term>AMS</term>
<listitem><para>Advanced Multi-threaded Server (&OBJ;).
<indexterm><primary>AMS</primary></indexterm>
<indexterm><primary>Advanced Multi-threaded Server</primary></indexterm>
</para></listitem>
</varlistentry>
<varlistentry>
<term>AFS</term>
<listitem><para>Andrew (distributed) Filesystem.
<indexterm><primary>AFS</primary></indexterm>
<indexterm><primary>Andrew Filesystem</primary></indexterm>
</para></listitem>
</varlistentry>
<varlistentry>
<term>CORBA</term>
<listitem><para>Common Object Request Broker Architecture, from the OMG.
<indexterm><primary>CORBA</primary></indexterm>
<indexterm><primary>OMG</primary></indexterm>
<indexterm><primary>Common Object Request Broker Architecture</primary></indexterm>
</para></listitem>
</varlistentry>
<varlistentry>
<term>HPSS</term>
<listitem><para>High Performance Storage System. A high-end mass storage
system developed by a consortium consisting of end-user sites
and commercial companies.
<indexterm><primary>HPSS</primary></indexterm>
<indexterm><primary>High Performance Storage System</primary></indexterm>
</para></listitem>
</varlistentry>
<varlistentry>
<term>NFS</term>
<listitem><para>Network Filesystem, developed by Sun.
<indexterm><primary>NFS</primary></indexterm>
<indexterm><primary>Network Filesystem</primary></indexterm>
</para></listitem>
</varlistentry>
<varlistentry>
<term>&OBJ;</term>
<listitem><para>Vendor of an ODBMS. Chosen at CERN in the framework of RD45.
<indexterm><primary>&OBJ;</primary></indexterm>
</para></listitem>
</varlistentry>
<varlistentry>
<term>ODBMS</term>
<listitem><para>Object Database Management System.
<indexterm><primary>ODBMS</primary></indexterm>
<indexterm><primary>Object Database Management System</primary></indexterm>
</para></listitem>
</varlistentry>
<varlistentry>
<term>ODL</term>
<listitem><para>Object Definition Language. Specification language defining the
interface to object types conforming to the ODMG Object Model.
<indexterm><primary>ODL</primary></indexterm>
<indexterm><primary>Object Definition Language</primary></indexterm>
</para></listitem>
</varlistentry>
<varlistentry>
<term>ODMG</term>
<listitem><para>Object Database Management Group. Develops standards for ODBMSes,
e.g., in the area of scalability, heterogeneity, WAN support
(distribution, replication, caching, recovery, etc.), and schema
evolution.
<indexterm><primary>ODMG</primary></indexterm>
<indexterm><primary>Object Database Management Group</primary></indexterm>
</para></listitem>
</varlistentry>
<varlistentry>
<term>OMG</term>
<listitem><para>Object Management Group.
Consortium of over 400 members from the software, hardware, and large
end-user communities, whose goal is to standardise and promote object
technology in all forms, in particular by proposing specific standards
which should increase portability of customer software across ODBMS
products.
<indexterm><primary>OMG</primary></indexterm>
<indexterm><primary>Object Management Group</primary></indexterm>
</para></listitem>
</varlistentry>
<varlistentry>
<term>ORB</term>
<listitem><para>Object Request Broker
<indexterm><primary>ORB</primary></indexterm>
<indexterm><primary>Object Request Broker</primary></indexterm>
</para></listitem>
</varlistentry>
<varlistentry>
<term>GEANT-4</term>
<listitem><para>Object-Oriented Toolkit for Simulation in HEP.
<indexterm><primary>GEANT 4</primary></indexterm>
</para></listitem>
</varlistentry>
<varlistentry>
<term>RD45 Project</term>
<listitem><para>Research and Development project to investigate object persistency
for HEP.
<indexterm><primary>RD45 Project</primary></indexterm>
</para></listitem>
</varlistentry>
</variablelist>
</chapter>
<!--
<index/>
-->
</book>

<!-- math example 
<informalequation>
<math><mrow>
<mi>&kappa;</mi><mo>=</mo> <mfrac> <mrow>
<mi>&xi;</mi></mrow><mrow><msub><mi>E</mi><mrow><mi>max </mi> </mrow>
</msub> </mrow> </mfrac> </mrow></math>
</informalequation>

<inlineequation><math><msub><mi>E</mi><mrow><mi>max </mi> </mrow> </msub>
</math></inlineequation> is the maximum transferable energy in a single
collision with an atomic electron. 
-->
