head     1.1;
access   ;
symbols  ;
locks    goossens:1.1; strict;
comment  @@;


1.1
date     94.03.14.14.50.40;  author goossens;  state Exp;
branches ;
next     ;


desc
@ Initial checkin
@



1.1
log
@Initial revision
@
text
@|4||||||||||||||)|||||||||||||||.|||||.|||||.|||||.|||||.|||||.%||||.%||||.%||||.%||||.%||||.A||||.]||||.]||||.k||||.k||||||||(|||||||||||||||||||||||||||||||||||||||||||||=|/||||||||p||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
›- 209 -
 
2.4.1 The maximum likelihood ratio.
 
The most important general tool for studying composite hypotheses is again based on tl-e likelihood function. It is the maximum likelihood ratio, defined as the ratio of the likelihood functions for the two hypotheses, each one maximized with respect to al
›l the free parameters. If there were no free parameters, this would correspond to the NeymanPearson test, which is optimal and calculable. Unfortunately, the effect of the free parameters makes the test not necessarily optimal, and in general one does not
› even know how to calculate a exactly.
 
Let us therefore restrict ourselves to the relatively common case where Ho and H1 have the same free parameters except that H1 has some parameters free whose values are fixed for Ho. for example:
 
Ho: ~ free, ~2=C
H1: ~1 free, ~z free
 
The maximum likelihood ratio is:
 
max f (x|01 ,~2=C)
 
max f(x~ 2)
 
where X is all the data, and the maximization is with respect to ~1 in the numerator and with respect to both ~ and ~2 in the denominator. Since the denominator is maximized over the same parameter as the numerator and in addition one more, clearly 0<~<1. 
›The difficulty in knowing the expected distribution of ~ arises from the fact that since the value of ~2 will in general be different for the two hypotheses, the value of ~1 will also be different due to the maximization, and the effect of the maximizatio
›n will depend on the correlation between ~1 and |2-
 
Asymptotically (for large amounts of data, or small errors on ~) the distribution of ~ is known, so this is normally used in evaluating its significance. Namely, the quantity -2 ln ~ is distributed as x2(r) where there are r more free parameters in the den
›ominator of ~ than in the numerator. Thus one evaluates the maximum likelihood ratio for the data, and looks up the value of -2 ln ~ in a table of chisquare with r degrees of freedom, which gives the significance level a. A small value of a is evidence ag
›ainst the more restrictive hypothesis Ho and in favor of the more general hypothesis H1.
 
2.5 SMALL-SAMPLE PROBLEMS.
 
The maximum likelihood ratio test and significance level calculation as defined above is widely used since it is nearly the only real statistical tool for this situation. Tt is however notoriously unreliable for small samples of data. Unfortunately, it is 
›hard to know exactly when a data sample is small, since it depends strongly on the hypotheses and distributions involved in ways which are not obvious.
_
 
- 212-
 
This is often called the chisquare function, because under the null hypothesis (that the histogram really comes from g(x)), the quantity t should be distributed like a x2 variable with n degrees of freedom if the number of bins is n. This is distribution-f
›ree since the expected distribution of t does not depend on g(x). If we fit another function with different data we would still use the same table Of ~2 to obtain the level of significance a.
 
3.3 COMPARING TWO ONE-DIMENSIONAL DISTRIBUTIONS.
 
In this section we will show what criteria may be used to choose a goodness-of-fit test by comparing two such tests for compatibility of onedimensional distributions. Both tests, the chisquare test mentioned above and the Kolmogorov test, may be used eithe
›r to compare two experimental samples of events or to compare an experimental sample with a completely-defined theoretical probability density.
 
3.3.1 The Chisquare test.
 
This test is defined just above for the fit of a one-dimensional experimental sample to a known curve g(x). It is easily generalised to compare two experimental distributions:
 
(m; - n;)2
 
t i m; ~ n;
 
We notice that this test requires the grouping of observations into bins (called by statisticians 'data classes') and does not prescribe exactly how this is to be done. We are in principle free to make as many bins as we want, and place the boundaries wher
›e we want. This arbitrariness, which clearly will affect the value of t and probably also its properties as a test statistic, is one of the undesireable features pointed out above.
 
In view of the popularity of the chisquare test, the subject of optimal binning has been the object of considerable study. We summarize here some results of these studies:
 
1. In order to increase the local power of the test, there should be as many bins as possible.
 
2. The upper limit on the number of bins comes from the requirement that t follow a ~2 distribution under the null hypothesis, which is only true for a 'large' number of events per bin, where the Poisson distribution becomes approximately Gaussian. Opinion
›s vary as to how many events are needed for this, but most studies indicate that there should be very few bins of less than ten events and no bins of less than five events.
- 213-
 
3. The distribution of bin boundaries is usually chosen equally spaced for practical reasons, but all studies indicate that it is better statistically if bins are chosen to be equally probable, that is, approximately the same number of events should fall i
›n each bin.
 
4. Additional experiment-dependent considerations, such as the accuracy with which x can be measured, may be important.
 
Another apparent source of arbitrariness is the exponent 2 in the expression for t. Any other positive non-zero exponent would give rise to an admissible test, although tl-e expected distributions for X~, x~, etc. would have to be recalculated. In fact it 
›can be shown using the theory of information that x2 is indeed optimal whenever the deviations in each bin are Gaussian (here they are in fact Poisson which is approximately Gaussian). The 'square' in 'chisquare' is therefore not at all arbitrary, and is 
›optimal for the usual case. One could, however, imagine cases where the measurements were not Gaussian-distributed and where a different test statistic would be better.
 
3.3.2 The Kolmoqorov test.
 
We now turn to a somewhat different kind of test, based on what the statisticians call the order statistics, which are nothing but the experimental observations ordered by increasing x-value. This allows us to form the cumulative distribution of the data S
›(x) as follows: The distribution starts at zero for x=-~, and increases by an amount 1~N at each point x where an experimental point x; has been observed. [N jS the total number of points observed, so S(+~)=1.1 We can use the Kolmogorov test either to com
›pare two experimental distributions S1(x) and Sz(x), containing respectively N1 and N2 events; or to compare S~(x) with a continuous known distribution of which the probability density function is f(x), and whose integral, the cumulative distribution func
›tion is F(x).
 
The Kolmogorov test statistic is a measure of the distance between the two distributions being compared. This measure is simply the largest distance (maximized with respect to x) between the two cumulative distributions:
 
D = JN max|S(x)-~(x)|         where S has N events,
 
or D = J(N1N2~(N1~N2)) maX|S1(X)-S2(X)|
 
It turns out that this test statistic is asvmPtoticallv distributionfree (that is, under the null hypothesis, the expected distribution of D is independent of S and F for large enough N.), and as written here it is correctly normalized to be also asymptoti
›cally independent of N, N1, and N2. The significance level a can be calculated from formulas or the table given in Eadie et al., page 270, or calculated by the CERN Program Library subroutine PROBKL.
- 216-
 
The permutation method allows us to measure the level of significance for any distance function a, without knowing the underlying distribution, assuming of course the null hypothesis. One first calculates the distance alz between point sets one and two. Th
›en the significance level is found as follows. Put both samples together to form a single sample of Nl+N2 points. Under the null hypothesis, this will also be distributed like sample 1 or sample 2, and any (random) partitioning of this pooled sample into 
›samples of N1 and N2 points should yield sets with the same distribution. We therefore make many different partitionings, each time choosing N1 points from the total N1+N2 points, and calculate a for each of these partitionings. If N1 and N2 are small eno
›ugh, we can actually enumerate all the partitionings possible.S Whether al 1 parti tionings are exhausted or only a random sample is used, the resulting distribution of tl-e values of a can be used in an obvious way to determine the significance of the ac
›tual value a~z corresponding to the observed data points. The significance level a is simply the proportion of al 1 a-values lying above the value a, z .
 
Now that the signi f icance level can be determined for any distance measure a, we return to the question of def ining such a distance. Since the procedure outlined above is valid for any measure a, we are free to choose a measure with physical significanc
›e for the situation at hand. For example, suppose we have treated a sample of mice in a certain way, and we wish to know if those mice are bigger than the ones in a sample which was not treated. We could take as the distance measure the average weight or 
›length of the treated mice minus the average of the untreated. If the treatment was expected to affect only half the treated mice, we could take the difference between the average weight of the heaviest treated mice and the heaviest untreated mice, etc.
 
In spite of this extraordinary freedom in choosing a test statistic, i t i s st i 11 d i f f i cu 1 t to f i nd 9 ood d i stance measures f or mu 1 t i var i ate data. A general procedure is given in Friedman (1974) using the k-nearest-neighbor concept. Th
›is is probably the best general method in use, although it suffers from at least two elements of arbitrariness:
 
1. The optimal number of nearest neighbors k is not general ly known.
 
2. It is somewhat dependent on the metric of the space in order to find the nearest neighbors. However, it is hard to imagine any measure of the distance between two point sets which does not depend on the definition of the distance between two points.
 
5 The total number of partitions of N1+N2 points into two samples of N and N2 points is:
 
P12 = (N1+N2)!~N1!N2!
 
This increases very fast with N1 and N2; for example, the number of ways of dividing a sample of 10 into two samples of 5 is only 252, but the number of ways of dividing a sample of 20 into two samples of 10 i s 1 84756 .
 
|6|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
@
